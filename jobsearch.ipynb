{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, we load the required libraries\n",
    "\n",
    "from cgitb import text\n",
    "from dataclasses import replace\n",
    "from gettext import gettext\n",
    "from msilib.schema import Class\n",
    "from operator import contains, countOf\n",
    "from os import getcwd, link\n",
    "from pickle import TRUE\n",
    "from typing import Mapping\n",
    "from unittest import result\n",
    "from xml.dom.minidom import Element\n",
    "from attr import attr, attrs\n",
    "from pyparsing import line\n",
    "#import pwd\n",
    "#from re import U\n",
    "#from tkinter import Button\n",
    "#from unicodedata import name\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import time\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "import requests\n",
    "import urllib.request\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import shutil\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from lxml import etree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------#\n",
    "#---Programm command lines for web scraping on Indeed----#\n",
    "#--------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#here we load the browser and the indeed website\n",
    "browser=webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "browser.get(\"https://ca.indeed.com/jobs?q=data%20analyst&l=Quebec%20Province\")\n",
    "\n",
    "time.sleep(3)   #this command force the programm to wait 3 seconds so to make sure the hole page has been loaded \n",
    "                #before executing the next commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function will return the path to a specific page on indeed\n",
    "def test(n):\n",
    "    next_path = f'//a[@aria-label=\"{n}\"]'   #path structure is obtained through the website html inspection\n",
    "    return next_path\n",
    "\n",
    "#this function return the end of url for each page\n",
    "def end_url(x):\n",
    "    if x > 1:\n",
    "        a = x - 1\n",
    "        end = '&start=' + f'{a}0'\n",
    "    else:\n",
    "        end = \"\"       #first page has no ending\n",
    "    return end\n",
    "\n",
    "# function to extract html document from given url\n",
    "def getHTML(url):\n",
    "    # request for HTML document of given url\n",
    "    response = requests.get(url, headers={\"Content-Type\":\"text\"})\n",
    "    # response will be provided in JSON format\n",
    "    return response.text\n",
    "\n",
    "#this function inform on the occurence of a specific string in the job description section\n",
    "def skill_test(x):\n",
    "    result = 'check website'\n",
    "    try:\n",
    "        string = sub_soup.find('div', attrs={'id':'jobDescriptionText'}).text\n",
    "        result_list = []\n",
    "        for each in x:        \n",
    "            result_list.append(each in string)  # append True/False for each element in substring\n",
    "        r = any(result_list) #call any() with boolean results list\n",
    "        if r == True:\n",
    "            result = 'yes'\n",
    "        else:\n",
    "            result = 'no'\n",
    "    except: pass\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#next lines allow to navigates through all the pages containing job announcement\n",
    "i = 0\n",
    "page = 1\n",
    "url = 'https://ca.indeed.com/jobs?q=data%20analyst&l=Quebec%20Province'\n",
    "\n",
    "jobtab = pd.DataFrame(columns=['TITLE', 'COMPANY', 'LOCATION', 'T_WORK', 'T_CONTRACT', 'SALARY', 'EXCEL', 'PYTHON', 'R', 'SAS', 'STATA', 'VBA', 'SQL', 'POWER_BI', 'WEBSITE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                TITLE  \\\n",
      "0   Data Analyst (Excel Specialist) - Analyste de ...   \n",
      "0   Analyste de données / Data Analyst (Excel Expert)   \n",
      "0                                    Business Analyst   \n",
      "0                                          BI Analyst   \n",
      "0                  Data Analyst (Marketing Campaigns)   \n",
      "..                                                ...   \n",
      "0        Data analyst (Business Intelligence Analyst)   \n",
      "0                      Senior Data Governance analyst   \n",
      "0                     Senior Business Systems Analyst   \n",
      "0                                             Careers   \n",
      "0       Logistics and customer service analyst intern   \n",
      "\n",
      "                    COMPANY       LOCATION  T_WORK                T_CONTRACT  \\\n",
      "0             New Alasko LP  Saint-leonard              -  Full-time, Casual   \n",
      "0                  Bouclair  Pointe-Claire  Remote      Full-time, Permanent   \n",
      "0                                 Gatineau                         Full-time   \n",
      "0                                 Montréal           -  Full-time, Permanent   \n",
      "0   Canadian Cancer Society       Montréal                                     \n",
      "..                      ...            ...     ...                       ...   \n",
      "0                Bombardier  Saint-Laurent                         Full-time   \n",
      "0               BNP Paribas       Montréal              Full-time, Permanent   \n",
      "0      Royal Bank of Canada       Montréal                         Full-time   \n",
      "0                                                                              \n",
      "0               Soucy Group  Drummondville                Internship / Co-op   \n",
      "\n",
      "                    SALARY                 EXCEL                PYTHON  \\\n",
      "0   $60,000–$70,000 a year                   yes                    no   \n",
      "0                                            yes                    no   \n",
      "0                                            yes                    no   \n",
      "0           $85,000 a year                    no                    no   \n",
      "0                                            yes                    no   \n",
      "..                     ...                   ...                   ...   \n",
      "0                                             no                    no   \n",
      "0                                            yes                    no   \n",
      "0                                             no                    no   \n",
      "0                           ERROR: check website  ERROR: check website   \n",
      "0                                            yes                    no   \n",
      "\n",
      "                       R                   SAS                 STATA  \\\n",
      "0                     no                    no                    no   \n",
      "0                     no                    no                    no   \n",
      "0                     no                    no                    no   \n",
      "0                     no                   yes                    no   \n",
      "0                     no                    no                    no   \n",
      "..                   ...                   ...                   ...   \n",
      "0                     no                   yes                    no   \n",
      "0                    yes                    no                    no   \n",
      "0                     no                    no                    no   \n",
      "0   ERROR: check website  ERROR: check website  ERROR: check website   \n",
      "0                     no                    no                    no   \n",
      "\n",
      "                     VBA                                            WEBSITE  \n",
      "0                     no  https://ca.indeed.com/pagead/clk?mo=r&ad=-6NYl...  \n",
      "0                    yes  https://ca.indeed.com/pagead/clk?mo=r&ad=-6NYl...  \n",
      "0                     no  https://ca.indeed.com/pagead/clk?mo=r&ad=-6NYl...  \n",
      "0                     no  https://ca.indeed.com/pagead/clk?mo=r&ad=-6NYl...  \n",
      "0                     no  https://ca.indeed.com/pagead/clk?mo=r&ad=-6NYl...  \n",
      "..                   ...                                                ...  \n",
      "0                     no  https://ca.indeed.com/rc/clk?jk=bc478ff899605f...  \n",
      "0                     no  https://ca.indeed.com/rc/clk?jk=4da75f583bb5ea...  \n",
      "0                     no  https://ca.indeed.com/rc/clk?jk=26bd66c55ff91d...  \n",
      "0   ERROR: check website  https://ca.indeed.com/rc/clk?jk=7bb0c9fb7c64a5...  \n",
      "0                     no  https://ca.indeed.com/rc/clk?jk=04b4b1553d84df...  \n",
      "\n",
      "[210 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "while i == 0:\n",
    "\n",
    "    main_url = url + end_url(page)\n",
    "    main_soup = BeautifulSoup(getHTML(main_url), \"html.parser\")\n",
    "    time.sleep(2)\n",
    "    \n",
    "    #these command lines may be used to get the total number of job href on a specific page\n",
    "    #num = 0\n",
    "    #for each in main_soup.find_all('a', attrs={'class':'jcs-JobTitle css-jspxzf eu4oa1w0'}):\n",
    "    #    num = num + 1\n",
    "    #num\n",
    "\n",
    "    for each in main_soup.find_all('a', attrs={'class':'jcs-JobTitle css-jspxzf eu4oa1w0'}):\n",
    "        sub_url = 'https://ca.indeed.com' + each['href']\n",
    "        sub_soup = BeautifulSoup(getHTML(sub_url), \"html.parser\")\n",
    "        time.sleep(2)\n",
    "        dom = etree.HTML(str(sub_soup))\n",
    "        time.sleep(2)\n",
    "        #all commands to report data from web pages to table will be there\n",
    "        #sub_soup = BeautifulSoup(getHTML('https://ca.indeed.com/viewjob?jk=d441350bc37c0f0f&tk=1g8gsuebnkoh7802&from=serp&vjs=3&advn=6781381351210116&adid=385033229&ad=-6NYlbfkN0AmeoOzMpFeQa4nQauBOkgcasiRGbz5T5YfctgmEyRynu_B7G8R18zY3QvB_OzxzaY3yyiQ7FsaOISXGcKdP7Sdb0zQD5paSCg5VZ9NrylfB-VeAZOe1qI2WAyu9d8CY98-ddxRqFa5ktFLYLkCs-N6NsGMJNMQTHHivD3D8VewI8oP_4OZ9oGhAjO2wGu0Amxn-csSve8XBrqV3CYzW1MAkcHr-NTpxXQTq3gfxFJ9U60tHps2-v7LjwE2t-xBx6gGJ8RelwXJ4nwcoH9DoSGez9Xu4DSyAJ4MLgtK52OeXWJFv5rMzTHgrL7xZ2aTkRp8ktj5Y2jqYgMSHS6T45pCF7RlWKla-RYfsUt1vsJAbHZeQslEYmMv&sjdu=9nrDNPdV1DghkDNnC2WJlW1nrk21-asFvjSk9jx-s_PLFBd88MMq2RphcBNLzZL8ANi7xzmMM98sKAS6e6UXGXsXz33hDQmoRdZsP3Oj0-csdU5LpWN0jxJTd7PMdyk_6RWWnthwO9obj2EY-ejpKp0ISMmTCPVnUpO1qfUHDapFg3uikRP50wodwhahAa3a4W3ywYYhd0gishNIvWGYVwNKgh7ZzNLwhHwj-pdjKDcI1Uu2unnsynKiS0GyXbDpYLShhFwgnTAIkcJAonCVV1RyCag4fH0hRj7VkqlSHeeWjRGbOqzPNsuaUO4sad-_hAr6kCfDQEUFQlJSwBsSjFDminH9LTrxZpwCJWJ1504d6t2Ca_8hDP9BSw1Qxgug'), \"html.parser\")\n",
    "        #dom = etree.HTML(str(sub_soup))\n",
    "\n",
    "        title = ''\n",
    "        comp_name = ''\n",
    "        location = ''\n",
    "        t_work = ''\n",
    "        t_contract =''\n",
    "        salary = ''\n",
    "        website = ''\n",
    "\n",
    "        try:\n",
    "            title = sub_soup.find('h1').text     #title of the post\n",
    "        except: pass\n",
    "        #sub_soup.find_all('h1')[0].text    #title of the post(other command)\n",
    "        #sub_soup.select('h1')[0].text   #title of the post(other command)\n",
    "\n",
    "        try:\n",
    "            comp_name = sub_soup.find('div', attrs={'class':'jobsearch-CompanyReview--heading'}).text      #name of the company\n",
    "        except: pass\n",
    "        #sub_soup.select('div.jobsearch-CompanyReview--heading')[0].text     #name of the company (other command)\n",
    "\n",
    "        try:\n",
    "            location = dom.xpath('//div[@class=\"icl-u-xs-mt--xs icl-u-textColor--secondary jobsearch-JobInfoHeader-subtitle jobsearch-DesktopStickyContainer-subtitle\"]//div[contains(text(),\"QC\")]')[0].text.replace(', QC','')\n",
    "        except: pass\n",
    "        #location = sub_soup.find('div', attrs='icl-Ratings-count').findNext('div').text.replace(', QC','')    #location of the job\n",
    "\n",
    "        #location.xpath('(.//following-sibling::div)[1]')\n",
    "        \n",
    "        try:\n",
    "            t_work = dom.xpath('//div[@class=\"icl-u-xs-mt--xs icl-u-textColor--secondary jobsearch-JobInfoHeader-subtitle jobsearch-DesktopStickyContainer-subtitle\"]//div[contains(text(),\"QC\")]/../following-sibling::div/div')[0].text\n",
    "        except: pass\n",
    "            \n",
    "        #t_work = sub_soup.find('div', attrs='icl-Ratings-count').findAllNext('div')[2].text  #type of working (remote or present)\n",
    "\n",
    "        try:\n",
    "            t_contract = sub_soup.find('span', attrs={'class':'jobsearch-JobMetadataHeader-item icl-u-xs-mt--xs'}).text      #type of contract (full time/part time, casual/permanent)\n",
    "        except: pass\n",
    "        #sub_soup.find('div', attrs={'id':'salaryInfoAndJobType'}).findAll('span')[1].text     #type of contract(other command)\n",
    "        \n",
    "        try:\n",
    "            salary = sub_soup.find('span', attrs={'class':'icl-u-xs-mr--xs attribute_snippet'}).text      #salary\n",
    "        except: pass\n",
    "\n",
    "        excel = skill_test(['Excel', 'excel', 'EXCEL'])   #check if SAS skill is required\n",
    "        python = skill_test(['Python', 'python', 'PYTHON'])   #check if SAS skill is required\n",
    "        r = skill_test(['R,', 'R.', 'R)'])   #check if R skill is required\n",
    "        sas = skill_test(['SAS'])   #check if SAS skill is required\n",
    "        stata = skill_test(['Stata', 'stata', 'STATA'])   #check if SAS skill is required\n",
    "        vba = skill_test(['VBA'])   #check if SAS skill is required\n",
    "        sql = skill_test(['SQL'])   #check if SQL skill is required\n",
    "        power_bi = skill_test(['Power BI', 'PowerBI', 'powerBI', 'power BI'])       #check if Power BI skill is required\n",
    "\n",
    "        website = sub_url\n",
    "\n",
    "                                                        #set the new line of observation       \n",
    "        obs = pd.DataFrame([[title, comp_name, location, t_work, t_contract, salary, excel, python, r, sas, stata, vba, sql, power_bi, website]], columns=['TITLE', 'COMPANY', 'LOCATION', 'T_WORK', 'T_CONTRACT', 'SALARY', 'EXCEL', 'PYTHON', 'R', 'SAS', 'STATA', 'VBA', 'SQL', 'POWER_BI', 'WEBSITE'])\n",
    "        \n",
    "        jobtab = pd.concat([jobtab, obs], axis=0)       #adding the new observation to the table\n",
    "        #jobtab = jobtab.append(obs)                     #other command possible (but will be deprecated soon)  \n",
    "\n",
    "    try:\n",
    "        page = page + 1\n",
    "        browser.find_element(By.XPATH, test(page)).click()     #change to next page\n",
    "        time.sleep(2)\n",
    "        if page == 2:\n",
    "            browser.find_element(By.XPATH, '//*[@id=\"popover-x\"]/button').click()       #close popup window\n",
    "        browser.execute_script(\"window.scrollTo(0,5000)\")\n",
    "    except NoSuchElementException:\n",
    "        i = 1\n",
    "\n",
    "print(jobtab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobtab.to_csv('draft/jobs.csv', index=False, encoding='UTF-8', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://ca.indeed.com/jobs?q=data%20analyst&l=Quebec%20Provincestart=130\n",
      "https://ca.indeed.com/rc/clk?jk=3ea31d41794c01fe&fccid=a7dc48a474db29d3&vjs=3\n"
     ]
    }
   ],
   "source": [
    "print(main_url)\n",
    "print(sub_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_soup.find('div', attrs={'id':'jobDescriptionText'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_f179c\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_f179c_level0_col0\" class=\"col_heading level0 col0\" >0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f179c_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_f179c_row0_col0\" class=\"data row0 col0\" ><a href=\"http://google.com\">val</a></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f179c_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_f179c_row1_col0\" class=\"data row1 col0\" ><a href=\"http://duckduckgo.com\">val</a></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1c3d31a99f0>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(['http://google.com', 'http://duckduckgo.com'])\n",
    "\n",
    "def make_clickable(val):\n",
    "    return '<a href=\"{}\">{}</a>'.format(val, 'val')\n",
    "\n",
    "df.style.format(make_clickable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_ff6c1\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_ff6c1_level0_col0\" class=\"col_heading level0 col0\" >0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ff6c1_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_ff6c1_row0_col0\" class=\"data row0 col0\" ><a href=\"http://google.com\">access website</a></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ff6c1_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_ff6c1_row1_col0\" class=\"data row1 col0\" ><a href=\"http://duckduckgo.com\">access website</a></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1c3d21a4700>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_clickable(link):\n",
    "    return '<a href=\"{}\">{}</a>'.format(link, 'access website')\n",
    "\n",
    "\n",
    "df.style.format(make_clickable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'HTML' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\user\\Desktop\\github\\web-scraping-job-offers\\jobsearch.ipynb Cellule 12\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/github/web-scraping-job-offers/jobsearch.ipynb#ch0000011?line=0'>1</a>\u001b[0m jobtab[\u001b[39m'\u001b[39m\u001b[39mWEBSITE\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m jobtab[\u001b[39m'\u001b[39m\u001b[39mWEBSITE\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m<a href=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhttp://softhints.com/tutorial/\u001b[39m\u001b[39m{\u001b[39;00mx\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m>\u001b[39m\u001b[39m{\u001b[39;00mx\u001b[39m}\u001b[39;00m\u001b[39m</a>\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/github/web-scraping-job-offers/jobsearch.ipynb#ch0000011?line=1'>2</a>\u001b[0m HTML(jobtab\u001b[39m.\u001b[39mto_html(escape\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'HTML' is not defined"
     ]
    }
   ],
   "source": [
    "jobtab['WEBSITE'] = jobtab['WEBSITE'].apply(lambda x: f'<a href=\"http://softhints.com/tutorial/{x}\">{x}</a>')\n",
    "HTML(jobtab.to_html(escape=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_clickable(val):\n",
    "    return f'<a target=\"_blank\" href=\"{val}\">{val}</a>'\n",
    "\n",
    "#jobtab.style.format({'url': make_clickable})\n",
    "jobtab"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fb4569285eef3a3450cb62085a5b1e0da4bce0af555edc33dcf29baf3acc1368"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
